{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "black_Resnext101 (1).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1tZo5szaslQ",
        "colab_type": "code",
        "outputId": "17f869fc-7dae-4458-aef6-cc91e73db0c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rs1Sjzb9bJ_H",
        "colab_type": "code",
        "outputId": "e4db6db4-e78b-46aa-a236-2818b058d0a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        }
      },
      "source": [
        "!pip install albumentations==0.4.3"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting albumentations==0.4.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/c4/a1e6ac237b5a27874b01900987d902fe83cc469ebdb09eb72a68c4329e78/albumentations-0.4.3.tar.gz (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 4.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from albumentations==0.4.3) (1.17.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from albumentations==0.4.3) (1.4.1)\n",
            "Collecting imgaug<0.2.7,>=0.2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/2e/748dbb7bb52ec8667098bae9b585f448569ae520031932687761165419a2/imgaug-0.2.6.tar.gz (631kB)\n",
            "\u001b[K     |████████████████████████████████| 634kB 31.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from albumentations==0.4.3) (3.13)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from albumentations==0.4.3) (4.1.2.30)\n",
            "Requirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python3.6/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations==0.4.3) (0.16.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations==0.4.3) (1.12.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.3) (2.4)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.3) (6.2.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.3) (2.4.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.3) (1.1.1)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.3) (3.1.3)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.3) (4.4.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.3) (2.4.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.3) (2.6.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.3) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.3) (0.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.3) (45.1.0)\n",
            "Building wheels for collected packages: albumentations, imgaug\n",
            "  Building wheel for albumentations (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for albumentations: filename=albumentations-0.4.3-cp36-none-any.whl size=60764 sha256=e4c23a6765f0c85da45d57601346e1e7b6b9e1ee1943df7f105e6b1478f6b09a\n",
            "  Stored in directory: /root/.cache/pip/wheels/20/16/8e/d3bec34bf30adff30929226f0b83cc8c005b5af131f51db9d0\n",
            "  Building wheel for imgaug (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imgaug: filename=imgaug-0.2.6-cp36-none-any.whl size=654020 sha256=55d5a71deaa7a9d84cbe70d9f6dac4120a5cbe4454a8a28ed6ba8a4f6cc94bd5\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/ec/48/0d25896c417b715af6236dbcef8f0bed136a1a5e52972fc6d0\n",
            "Successfully built albumentations imgaug\n",
            "Installing collected packages: imgaug, albumentations\n",
            "  Found existing installation: imgaug 0.2.9\n",
            "    Uninstalling imgaug-0.2.9:\n",
            "      Successfully uninstalled imgaug-0.2.9\n",
            "  Found existing installation: albumentations 0.1.12\n",
            "    Uninstalling albumentations-0.1.12:\n",
            "      Successfully uninstalled albumentations-0.1.12\n",
            "Successfully installed albumentations-0.4.3 imgaug-0.2.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kPSwISobRVD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function, division, absolute_import\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "# Any results you write to the current directory are saved as output.\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from torchvision import transforms,models\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "import math\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "\n",
        "from PIL import Image, ImageOps, ImageEnhance\n",
        "from albumentations.core.transforms_interface import ImageOnlyTransform\n",
        "\n",
        "from albumentations import (\n",
        "    PadIfNeeded,\n",
        "    GaussianBlur,\n",
        "    Flip,\n",
        "    HorizontalFlip,\n",
        "    Transpose,\n",
        "    VerticalFlip,    \n",
        "    CenterCrop,    \n",
        "    Crop,\n",
        "    Compose,\n",
        "    Transpose,\n",
        "    RandomRotate90,\n",
        "    ElasticTransform,\n",
        "    GridDistortion, \n",
        "    OpticalDistortion,\n",
        "    RandomSizedCrop,\n",
        "    OneOf,\n",
        "    CLAHE,\n",
        "    Rotate,\n",
        "    RandomBrightnessContrast,    \n",
        "    RandomGamma,\n",
        "    ShiftScaleRotate ,\n",
        "    GaussNoise,\n",
        "    Blur,\n",
        "    MotionBlur\n",
        ")\n",
        "my_size = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXv3_H3H8FPi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Cutout:\n",
        "    def __init__(self, mask_size, p, cutout_inside, mask_color=1):\n",
        "        self.p = p\n",
        "        self.mask_size = mask_size\n",
        "        self.cutout_inside = cutout_inside\n",
        "        self.mask_color = mask_color\n",
        "\n",
        "        self.mask_size_half = mask_size // 2\n",
        "        self.offset = 1 if mask_size % 2 == 0 else 0\n",
        "\n",
        "    def __call__(self, image):\n",
        "        image = np.asarray(image).copy()\n",
        "\n",
        "        if np.random.random() > self.p:\n",
        "            return image\n",
        "\n",
        "        h, w = image.shape[:2]\n",
        "\n",
        "        if self.cutout_inside:\n",
        "            cxmin, cxmax = self.mask_size_half, w + self.offset - self.mask_size_half\n",
        "            cymin, cymax = self.mask_size_half, h + self.offset - self.mask_size_half\n",
        "        else:\n",
        "            cxmin, cxmax = 0, w + self.offset\n",
        "            cymin, cymax = 0, h + self.offset\n",
        "\n",
        "        cx = np.random.randint(cxmin, cxmax)\n",
        "        cy = np.random.randint(cymin, cymax)\n",
        "        xmin = cx - self.mask_size_half\n",
        "        ymin = cy - self.mask_size_half\n",
        "        xmax = xmin + self.mask_size\n",
        "        ymax = ymin + self.mask_size\n",
        "        xmin = max(0, xmin)\n",
        "        ymin = max(0, ymin)\n",
        "        xmax = min(w, xmax)\n",
        "        ymax = min(h, ymax)\n",
        "        image[ymin:ymax, xmin:xmax] = self.mask_color\n",
        "        return image\n",
        "\n",
        "\n",
        "class DualCutout:\n",
        "    def __init__(self, mask_size, p, cutout_inside, mask_color=1):\n",
        "        self.cutout = Cutout(mask_size, p, cutout_inside, mask_color)\n",
        "\n",
        "    def __call__(self, image):\n",
        "        return np.hstack([self.cutout(image), self.cutout(image)])\n",
        "\n",
        "\n",
        "class DualCutoutCriterion:\n",
        "    def __init__(self, alpha):\n",
        "        self.alpha = alpha\n",
        "        self.criterion = nn.CrossEntropyLoss(reduction='mean')\n",
        "\n",
        "    def __call__(self, preds, targets):\n",
        "        preds1, preds2 = preds\n",
        "        return (self.criterion(preds1, targets) + self.criterion(\n",
        "            preds2, targets)) * 0.5 + self.alpha * F.mse_loss(preds1, preds2)\n",
        "\n",
        "\n",
        "def mixup(data, targets, alpha, n_classes):\n",
        "    indices = torch.randperm(data.size(0))\n",
        "    shuffled_data = data[indices]\n",
        "    shuffled_targets = targets[indices]\n",
        "\n",
        "    lam = np.random.beta(alpha, alpha)\n",
        "    data = data * lam + shuffled_data * (1 - lam)\n",
        "    targets = (targets, shuffled_targets, lam)\n",
        "\n",
        "    return data, targets\n",
        "\n",
        "\n",
        "def mixup_criterion(preds, targets):\n",
        "    targets1, targets2, lam = targets\n",
        "    criterion = nn.CrossEntropyLoss(reduction='mean')\n",
        "    return lam * criterion(preds, targets1) + (1 - lam) * criterion(\n",
        "        preds, targets2)\n",
        "    \n",
        "\n",
        "\n",
        "class RandomErasing:\n",
        "    def __init__(self, p, area_ratio_range, min_aspect_ratio, max_attempt):\n",
        "        self.p = p\n",
        "        self.max_attempt = max_attempt\n",
        "        self.sl, self.sh = area_ratio_range\n",
        "        self.rl, self.rh = min_aspect_ratio, 1. / min_aspect_ratio\n",
        "\n",
        "    def __call__(self, image):\n",
        "        image = np.asarray(image).copy()\n",
        "\n",
        "        if np.random.random() > self.p:\n",
        "            return image\n",
        "\n",
        "        h, w = image.shape[:2]\n",
        "        image_area = h * w\n",
        "\n",
        "        for _ in range(self.max_attempt):\n",
        "            mask_area = np.random.uniform(self.sl, self.sh) * image_area\n",
        "            aspect_ratio = np.random.uniform(self.rl, self.rh)\n",
        "            mask_h = int(np.sqrt(mask_area * aspect_ratio))\n",
        "            mask_w = int(np.sqrt(mask_area / aspect_ratio))\n",
        "\n",
        "            if mask_w < w and mask_h < h:\n",
        "                x0 = np.random.randint(0, w - mask_w)\n",
        "                y0 = np.random.randint(0, h - mask_h)\n",
        "                x1 = x0 + mask_w\n",
        "                y1 = y0 + mask_h\n",
        "                image[y0:y1, x0:x1] = np.random.uniform(0, 1)\n",
        "                break\n",
        "        return image  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2TqIEwFbRi6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_aug = Compose([ \n",
        "    ShiftScaleRotate(p=1,border_mode=cv2.BORDER_CONSTANT,value =1),\n",
        "    OneOf([\n",
        "        GridDistortion(distort_limit =0.05 ,border_mode=cv2.BORDER_CONSTANT,value =1, p=0.1),\n",
        "        OpticalDistortion(p=0.1, distort_limit= 0.05, shift_limit=0.2,border_mode=cv2.BORDER_CONSTANT,value =1)                  \n",
        "        ], p=0.3),\n",
        "    OneOf([\n",
        "        Blur(),\n",
        "        GaussianBlur(blur_limit=3)\n",
        "        ], p=0.4),    \n",
        "    RandomGamma(p=0.5)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmq_HfHWb0Vw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ToTensor:\n",
        "    def __call__(self, data):\n",
        "        if isinstance(data, tuple):\n",
        "            return tuple([self._to_tensor(image) for image in data])\n",
        "        else:\n",
        "            return self._to_tensor(data)\n",
        "\n",
        "    def _to_tensor(self, data):\n",
        "        if len(data.shape) == 3:\n",
        "            return torch.from_numpy(data.transpose(2, 0, 1).astype(np.float32))\n",
        "        else:\n",
        "            return torch.from_numpy(data[None, :, :].astype(np.float32))\n",
        "\n",
        "\n",
        "class Normalize:\n",
        "    def __init__(self, mean, std):\n",
        "        self.mean = np.array(mean)\n",
        "        self.std = np.array(std)\n",
        "\n",
        "    def __call__(self, image):\n",
        "        image = np.asarray(image).astype(np.float32) / 255.\n",
        "        image = (image - self.mean) / self.std\n",
        "        return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XH5debhb0do",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Selayer(nn.Module):\n",
        "\n",
        "    def __init__(self, inplanes):\n",
        "        super(Selayer, self).__init__()\n",
        "        self.global_avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.conv1 = nn.Conv2d(inplanes, int(inplanes / 16), kernel_size=1, stride=1)\n",
        "        self.conv2 = nn.Conv2d(int(inplanes / 16), inplanes, kernel_size=1, stride=1)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        out = self.global_avgpool(x)\n",
        "\n",
        "        out = self.conv1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.sigmoid(out)\n",
        "\n",
        "        return x * out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, cardinality, stride=1, downsample=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes * 2, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes * 2)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(planes * 2, planes * 2, kernel_size=3, stride=stride,\n",
        "                               padding=1, groups=cardinality, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes * 2)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(planes * 2, planes * 4, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
        "\n",
        "        self.selayer = Selayer(planes * 4)\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        out = self.selayer(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class SeResNeXt(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, cardinality=32, num_classes=1000):\n",
        "        super(SeResNeXt, self).__init__()\n",
        "        self.cardinality = cardinality\n",
        "        self.inplanes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "                if m.bias is not None:\n",
        "                    m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, self.cardinality, stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes, self.cardinality))\n",
        "                             \n",
        "        # vowel_diacritic\n",
        "        self.fc1 = nn.Linear(2048,11)\n",
        "        # grapheme_root\n",
        "        self.fc2 = nn.Linear(2048,168)\n",
        "        # consonant_diacritic\n",
        "        self.fc3 = nn.Linear(2048,7)\n",
        "        return nn.Sequential(*layers)\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        \n",
        "        x1 = self.fc1(x)\n",
        "        x2 = self.fc2(x)\n",
        "        x3 = self.fc3(x)\n",
        "        \n",
        "        return x1,x2,x3\n",
        "\n",
        "\n",
        "def se_resnext50(**kwargs):\n",
        "    \"\"\"Constructs a SeResNeXt-50 model.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = SeResNeXt(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
        "    return model\n",
        "\n",
        "\n",
        "def se_resnext101(**kwargs):\n",
        "    \"\"\"Constructs a SeResNeXt-101 model.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = SeResNeXt(Bottleneck, [3, 4, 23, 3], **kwargs)\n",
        "    return model\n",
        "\n",
        "\n",
        "def se_resnext152(**kwargs):\n",
        "    \"\"\"Constructs a SeResNeXt-152 model.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = SeResNeXt(Bottleneck, [3, 8, 36, 3], **kwargs)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJOYU7Jub0go",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv('/content/drive/My Drive/nipuyo/train.csv')\n",
        "data0 = pd.read_feather('/content/drive/My Drive/black_128/train_data_00_l.feather')\n",
        "data1 = pd.read_feather('/content/drive/My Drive/black_128/train_data_11_l.feather')\n",
        "data2 = pd.read_feather('/content/drive/My Drive/black_128/train_data_22_l.feather')  \n",
        "data3 = pd.read_feather('/content/drive/My Drive/black_128/train_data_33_l.feather')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKQODstTbRlt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_full = pd.concat([data0,data1,data2,data3],ignore_index=True)\n",
        "del data0,data1,data2,data3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPK0Avm4c7Ju",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GraphemeDataset(Dataset):\n",
        "    def __init__(self,df,label,_type='train',transform =True,aug = train_aug):\n",
        "        self.df = df\n",
        "        self.label = label\n",
        "        self.aug = aug\n",
        "        self.transform = transform\n",
        "        self.data = df.iloc[:, 1:].values\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    def __getitem__(self,idx):\n",
        "        label1 = self.label.vowel_diacritic.values[idx]\n",
        "        label2 = self.label.grapheme_root.values[idx]\n",
        "        label3 = self.label.consonant_diacritic.values[idx]\n",
        "        image = self.data[idx, :].reshape(my_size,my_size).astype(np.float)\n",
        "        if self.transform: \n",
        "            #out = np.empty((my_size, my_size, 3), dtype=np.uint8)#converting to 3channel image\n",
        "            #out[:, :, 0] = image\n",
        "            #out[:, :, 1] = image\n",
        "            #out[:, :, 2] = image\n",
        "            #print(image.shape)\n",
        "            augment = self.aug(image = image)\n",
        "            image = augment['image']\n",
        "            cutout = Cutout(10,0.3,True,1)\n",
        "            image = cutout(image)\n",
        "        #norm = Normalize([0.0692],[0.2051])\n",
        "        #image = norm(image)\n",
        "        return image,label1,label2,label3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f57kTxZVdFAB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df , valid_df = train_test_split(train,test_size=0.20, random_state=42,shuffle=True) ## Split Labels\n",
        "data_train_df, data_valid_df = train_test_split(data_full,test_size=0.20, random_state=42,shuffle =True) ## split data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPOKdqzcdFL1",
        "colab_type": "code",
        "outputId": "482ff176-8fe2-4872-9859-d112e1e8a053",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "305"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hV0GuCVdFPC",
        "colab_type": "code",
        "outputId": "a655306b-0a08-44cd-de1b-93c791474f9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "train_dataset = GraphemeDataset(data_train_df ,train_df,transform = True) \n",
        "valid_dataset = GraphemeDataset(data_valid_df ,valid_df,transform = False) \n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOrS3XaWdFYs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def visualize(original_image,aug_image):\n",
        "    fontsize = 18\n",
        "    f, ax = plt.subplots(1, 2, figsize=(8, 8))\n",
        "    ax[0].imshow(original_image, cmap='gray')\n",
        "    ax[0].set_title('Original image', fontsize=fontsize)\n",
        "    ax[1].imshow(aug_image,cmap='gray')\n",
        "    ax[1].set_title('Augmented image', fontsize=fontsize)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKcAXBKTdp6z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "orig_image = data_train_df.iloc[0, 1:].values.reshape(128,128).astype(np.float)\n",
        "aug_image = train_dataset[0][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBq-eWCKdxKu",
        "colab_type": "code",
        "outputId": "707625f7-5b59-4a16-9448-8a45ce470b5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        }
      },
      "source": [
        "for i in range (1):\n",
        "    aug_image = train_dataset[0][0]\n",
        "    visualize (orig_image,aug_image)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAewAAAD+CAYAAAD4QzZEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POy0B7pNdxWg",
        "colab_type": "code",
        "outputId": "9562b7b7-4104-4787-b18f-d1789bde7e74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "del train_df,valid_df,data_train_df,data_valid_df \n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4673"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOWhnIWldxZ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_dataset,batch_size=batch_size,shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrZYg1JHeJqU",
        "colab_type": "code",
        "outputId": "f70de8c6-b5e8-49e7-d360-b16caaf3f77c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "model = se_resnext50().to(device)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwCgfGtZeJ6I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer =torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 5, 2e-4)\n",
        "#criterion = nn.CrossEntropyLoss()\n",
        "batch_size=32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_yV0oh93dIH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ohem_loss( rate, cls_pred, cls_target ):\n",
        "\n",
        "    batch_size = cls_pred.size(0) \n",
        "    ohem_cls_loss = F.cross_entropy(cls_pred, cls_target, reduction='none', ignore_index=-1)\n",
        "\n",
        "    sorted_ohem_loss, idx = torch.sort(ohem_cls_loss, descending=True)\n",
        "    keep_num = min(sorted_ohem_loss.size()[0], int(batch_size*rate) )\n",
        "    if keep_num < sorted_ohem_loss.size()[0]:\n",
        "        keep_idx_cuda = idx[:keep_num]\n",
        "        ohem_cls_loss = ohem_cls_loss[keep_idx_cuda]\n",
        "    cls_loss = ohem_cls_loss.sum() / keep_num\n",
        "    return cls_loss\n",
        "\n",
        "\n",
        "def rand_bbox(size, lam):\n",
        "    W = size[2]\n",
        "    H = size[3]\n",
        "    cut_rat = np.sqrt(1. - lam)\n",
        "    cut_w = np.int(W * cut_rat)\n",
        "    cut_h = np.int(H * cut_rat)\n",
        "\n",
        "    # uniform\n",
        "    cx = np.random.randint(W)\n",
        "    cy = np.random.randint(H)\n",
        "\n",
        "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
        "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
        "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
        "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
        "\n",
        "    return bbx1, bby1, bbx2, bby2\n",
        "def cutmix(data, targets1, targets2, targets3, alpha):\n",
        "    indices = torch.randperm(data.size(0))\n",
        "    shuffled_data = data[indices]\n",
        "    shuffled_targets1 = targets1[indices]\n",
        "    shuffled_targets2 = targets2[indices]\n",
        "    shuffled_targets3 = targets3[indices]\n",
        "\n",
        "    lam = np.random.beta(alpha, alpha)\n",
        "    bbx1, bby1, bbx2, bby2 = rand_bbox(data.size(), lam)\n",
        "    data[:, :, bbx1:bbx2, bby1:bby2] = data[indices, :, bbx1:bbx2, bby1:bby2]\n",
        "    # adjust lambda to exactly match pixel ratio\n",
        "    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (data.size()[-1] * data.size()[-2]))\n",
        "\n",
        "    targets = [targets1, shuffled_targets1, targets2, shuffled_targets2, targets3, shuffled_targets3, lam]\n",
        "    return data, targets\n",
        "# loss \n",
        "def cutmix_criterion(preds1,preds2,preds3, targets, rate=0.7):\n",
        "    targets1, targets2,targets3, targets4,targets5, targets6, lam = targets[0], targets[1], targets[2], targets[3], targets[4], targets[5], targets[6]\n",
        "    criterion = nn.CrossEntropyLoss(reduction='mean')\n",
        "    #criterion = ohem_loss\n",
        "    lo1 = lam * criterion(preds1, targets1) + (1 - lam) * criterion(preds1, targets2)\n",
        "    lo2 = lam * criterion(preds2, targets3) + (1 - lam) * criterion(preds2, targets4)\n",
        "    lo3 = lam * criterion(preds3, targets5) + (1 - lam) * criterion(preds3, targets6)\n",
        "    return lo1,lo2,lo3\n",
        "\n",
        "\n",
        "def mixup(data, targets1, targets2, targets3, alpha):\n",
        "    indices = torch.randperm(data.size(0))\n",
        "    shuffled_data = data[indices]\n",
        "    shuffled_targets1 = targets1[indices]\n",
        "    shuffled_targets2 = targets2[indices]\n",
        "    shuffled_targets3 = targets3[indices]\n",
        "\n",
        "    lam = np.random.beta(alpha, alpha)\n",
        "    data = data * lam + shuffled_data * (1 - lam)\n",
        "    targets = [targets1, shuffled_targets1, targets2, shuffled_targets2, targets3, shuffled_targets3, lam]\n",
        "\n",
        "    return data, targets\n",
        "\n",
        "\n",
        "def mixup_criterion(preds1,preds2,preds3, targets, rate=0.7):\n",
        "    targets1, targets2,targets3, targets4,targets5, targets6, lam = targets[0], targets[1], targets[2], targets[3], targets[4], targets[5], targets[6]\n",
        "    criterion = nn.CrossEntropyLoss(reduction='mean')\n",
        "    #criterion = ohem_loss\n",
        "    lo1 = lam * criterion(preds1, targets1) + (1 - lam) * criterion(preds1, targets2)\n",
        "    lo2 = lam * criterion(preds2, targets3) + (1 - lam) * criterion(preds2, targets4)\n",
        "    lo3 = lam * criterion(preds3, targets5) + (1 - lam) * criterion(preds3, targets6)\n",
        "    return  lo1,lo2,lo3 \n",
        "    #return [ lam * criterion(rate, preds1, targets1) + (1 - lam) * criterion(rate, preds1, targets2), lam * criterion(rate, preds2, targets3) + (1 - lam) * criterion(rate, preds2, targets4), lam * criterion(rate, preds3, targets5) + (1 - lam) * criterion(rate, preds3, targets6) ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfJQNzxheJ9h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy\n",
        "def train(epoch):\n",
        "  model.train()\n",
        "  losses = []\n",
        "  accs = []\n",
        "  acc= 0.0\n",
        "  total = 0.0\n",
        "  running_loss = 0.0\n",
        "  running_acc = 0.0\n",
        "  val_now_acc = 0.0\n",
        "  for idx, (inputs,labels1,labels2,labels3) in enumerate(train_loader):\n",
        "      inputs = inputs.to(device)\n",
        "      labels1 = labels1.to(device)\n",
        "      labels2 = labels2.to(device)\n",
        "      labels3 = labels3.to(device)\n",
        "      total += len(inputs)\n",
        "      optimizer.zero_grad()\n",
        "      inputs, targets = mixup(inputs, labels1, labels2, labels3, 0.4)\n",
        "      outputs1, outputs2, outputs3 = model(inputs.unsqueeze(1).float())\n",
        "      loss1,loss2,loss3 = mixup_criterion(outputs1,outputs2,outputs3, targets) \n",
        "\n",
        "      running_loss += loss1.item()+loss2.item()+loss3.item()\n",
        "      running_acc += (outputs1.argmax(1)==labels1).float().mean()\n",
        "      running_acc += (outputs2.argmax(1)==labels2).float().mean()\n",
        "      running_acc += (outputs3.argmax(1)==labels3).float().mean()\n",
        "      (loss1+loss2+loss3).backward()\n",
        "      optimizer.step()\n",
        "      acc = running_acc/total\n",
        "      #scheduler.step()\n",
        "  \n",
        "  losses.append(running_loss/len(train_loader))\n",
        "  accs.append(running_acc/(len(train_loader)*3))\n",
        "  print(' train epoch : {}\\tacc : {:.2f}%'.format(epoch,running_acc/(len(train_loader)*3)))\n",
        "  print('loss : {:.4f}'.format(running_loss/len(train_loader)))\n",
        "  torch.save(model.state_dict(), 'resnext.pth') ## Saving model weights\n",
        "  torch.cuda.empty_cache()\n",
        "  gc.collect()\n",
        "  return losses , accs\n",
        "    \n",
        "def evaluate(epoch):\n",
        "   model.eval()\n",
        "   losses = []\n",
        "   accs = []\n",
        "   acc= 0.0\n",
        "   total = 0.0\n",
        "   #print('epochs {}/{} '.format(epoch+1,epochs))\n",
        "   running_loss = 0.0\n",
        "   running_acc = 0.0\n",
        "   with torch.no_grad():\n",
        "     for idx, (inputs,labels1,labels2,labels3) in enumerate(valid_loader):\n",
        "        inputs = inputs.to(device)\n",
        "        labels1 = labels1.to(device)\n",
        "        labels2 = labels2.to(device)\n",
        "        labels3 = labels3.to(device)\n",
        "        total += len(inputs)\n",
        "        inputs, targets = mixup(inputs, labels1, labels2, labels3, 0.4)\n",
        "        outputs1,outputs2,outputs3 = model(inputs.unsqueeze(1).float())\n",
        "        loss1_val,loss2_val,loss3_val = mixup_criterion(outputs1,outputs2,outputs3, targets)  \n",
        "\n",
        "        running_loss += loss1_val.item()+loss2_val.item()+loss3_val.item()\n",
        "        running_acc += (outputs1.argmax(1)==labels1).float().mean()\n",
        "        running_acc += (outputs2.argmax(1)==labels2).float().mean()\n",
        "        running_acc += (outputs3.argmax(1)==labels3).float().mean()\n",
        "      \n",
        "        acc = running_acc/total\n",
        "        #scheduler.step()\n",
        "         \n",
        "   losses.append(running_loss/len(valid_loader))\n",
        "   accs.append(running_acc/(len(valid_loader)*3))\n",
        "   print('val epoch: {} \\tval acc : {:.2f}%'.format(epoch,running_acc/(len(valid_loader)*3)))\n",
        "   print('loss : {:.4f}'.format(running_loss/len(valid_loader)))\n",
        "   val_acc_now = running_acc/(len(valid_loader)*3)\n",
        "   return losses , accs , val_acc_now"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVbQTFpWeKBA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "outputId": "8a65f2d0-9a97-457c-a23d-21faa1595510"
      },
      "source": [
        "%%time\n",
        "n_epochs = 5\n",
        "best_val_acc = 0.0\n",
        "for epoch in range(n_epochs):\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    tain_losses,train_accs = train(epoch)\n",
        "    valid_losses,valid_accs,val_acc_now = evaluate(epoch)\n",
        "    if val_acc_now > best_val_acc:\n",
        "      print(f'Validation accuracy has increased from:  {best_val_acc:.4f} to: {val_acc_now:.4f}. Saving checkpoint')\n",
        "      #torch.save(model.state_dict(), '/content/drive/My Drive/black_128/se_resnext101.pth')\n",
        "      best_val_acc = val_acc_now"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " train epoch : 0\tacc : 0.57%\n",
            "loss : 2.6576\n",
            "val epoch: 0 \tval acc : 0.58%\n",
            "loss : 2.4926\n",
            "Validation accuracy has increased from:  0.0000 to: 0.5763. Saving checkpoint\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGR3689JLLIP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdHmxbsmeJ3k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history.to_csv('history.csv')\n",
        "history.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrLe6AZlIKrd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Any results you write to the current directory are saved as output.\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from torchvision import transforms,models\n",
        "from tqdm import tqdm_notebook as tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGtrdRpyIK52",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = pd.read_csv('/content/drive/My Drive/begali comp/bengaliai-cv19/test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiIpfG94IRFo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GraphemeDataset(Dataset):\n",
        "    def __init__(self,df,_type='train'):\n",
        "        self.df = df\n",
        "        self.data = df.iloc[:, 1:].values\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    def __getitem__(self,idx):\n",
        "        name = self.df.iloc[idx,0]\n",
        "        #image = self.df.iloc[idx][1:].values.reshape(128,128).astype(float)\n",
        "        image = self.data[idx, :].reshape(128,128).astype(np.float)\n",
        "        return image,name"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbMlKz60IRZd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data = ['test_image_data_0.parquet','test_image_data_1.parquet','test_image_data_2.parquet','test_image_data_3.parquet']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iKwJWnqNn5F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HEIGHT = 137\n",
        "WIDTH = 236\n",
        "SIZE = 128\n",
        "\n",
        "def bbox(img):\n",
        "    rows = np.any(img, axis=1)\n",
        "    cols = np.any(img, axis=0)\n",
        "    rmin, rmax = np.where(rows)[0][[0, -1]]\n",
        "    cmin, cmax = np.where(cols)[0][[0, -1]]\n",
        "    return rmin, rmax, cmin, cmax\n",
        "\n",
        "def crop_resize(img0, size=SIZE, pad=16):\n",
        "    #crop a box around pixels large than the threshold \n",
        "    #some images contain line at the sides\n",
        "    ymin,ymax,xmin,xmax = bbox(img0[5:-5,5:-5] > 80)\n",
        "    #cropping may cut too much, so we need to add it back\n",
        "    xmin = xmin - 13 if (xmin > 13) else 0\n",
        "    ymin = ymin - 10 if (ymin > 10) else 0\n",
        "    xmax = xmax + 13 if (xmax < WIDTH - 13) else WIDTH\n",
        "    ymax = ymax + 10 if (ymax < HEIGHT - 10) else HEIGHT\n",
        "    img = img0[ymin:ymax,xmin:xmax]\n",
        "    #remove lo intensity pixels as noise\n",
        "    img[img < 28] = 0\n",
        "    lx, ly = xmax-xmin,ymax-ymin\n",
        "    l = max(lx,ly) + pad\n",
        "    #make sure that the aspect ratio is kept in rescaling\n",
        "    img = np.pad(img, [((l-ly)//2,), ((l-lx)//2,)], mode='constant')\n",
        "    return cv2.resize(img,(size,size))\n",
        "\n",
        "def Resize(df,size=128):\n",
        "    resized = {} \n",
        "    df = df.set_index('image_id')\n",
        "    for i in tqdm(range(df.shape[0])):\n",
        "       # image = cv2.resize(df.loc[df.index[i]].values.reshape(137,236),(size,size))\n",
        "        image0 = 255 - df.loc[df.index[i]].values.reshape(137,236).astype(np.uint8)\n",
        "    #normalize each image by its max val\n",
        "        img = (image0*(255.0/image0.max())).astype(np.uint8)\n",
        "        image = crop_resize(img)\n",
        "        resized[df.index[i]] = image.reshape(-1)\n",
        "    resized = pd.DataFrame(resized).T.reset_index()\n",
        "    resized.columns = resized.columns.astype(str)\n",
        "    resized.rename(columns={'index':'image_id'},inplace=True)\n",
        "    return resized"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzgFiHAHIRkQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "## Inference a little faster using @Iafoss and  @peters technique\n",
        "row_id,target = [],[]\n",
        "for fname in test_data:\n",
        "    data = pd.read_parquet(f'/content/drive/My Drive/begali comp/bengaliai-cv19/{fname}')\n",
        "    data = Resize(data)\n",
        "    test_image = GraphemeDataset(data)\n",
        "    dl = torch.utils.data.DataLoader(test_image,batch_size=128,num_workers=4,shuffle=False)\n",
        "    with torch.no_grad():\n",
        "        for x,y in tqdm(dl):\n",
        "            x = x.unsqueeze(1).float().cuda()\n",
        "            p1,p2,p3 = model(x)\n",
        "            p1 = p1.argmax(-1).view(-1).cpu()\n",
        "            p2 = p2.argmax(-1).view(-1).cpu()\n",
        "            p3 = p3.argmax(-1).view(-1).cpu()\n",
        "            for idx,name in enumerate(y):\n",
        "                row_id += [f'{name}_vowel_diacritic',f'{name}_grapheme_root',\n",
        "                           f'{name}_consonant_diacritic']\n",
        "                target += [p1[idx].item(),p2[idx].item(),p3[idx].item()]\n",
        "                \n",
        "sub_df = pd.DataFrame({'row_id': row_id, 'target': target})\n",
        "sub_df.to_csv('submission.csv', index=False)\n",
        "sub_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1gnaNVsNuqD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub_df"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}